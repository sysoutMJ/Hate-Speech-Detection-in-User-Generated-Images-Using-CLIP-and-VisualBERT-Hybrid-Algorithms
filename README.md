# Hate-Speech-Detection-in-User-Generated-Images-Using-CLIP-and-VisualBERT-Hybrid-Algorithms

A final project created in partial fulfillment of the courses Thesis 1 and Thesis 2.

This project presents a hybridized VisualBERT and CLIP model trained for detecting hate speech in user-generated images.
The hybrid model is deployed in a gallery application featuring various functionalities, including:

## Features

- Analytics dashboard
- Single-image and batch exploration modes
- Dedicated page for flagged (hate speech) images
- Explainability interface showing model reasoning

## Contributors

- Marcus Joseph Geneston — Model Development, Full-Stack Development, System Integration
- Andrea Lituania — Full-Stack Development
- Jeremy Charles Mora — Full-Stack Development

## Note

Due to access restrictions, course-specific documents used in this project are not included in this repository.
